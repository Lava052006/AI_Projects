##ðŸ§  AI Code Feedback System

An **AI-powered code review platform** that analyzes user-written code and provides **structured, actionable feedback** on code quality, readability, best practices, and potential issues.

This project is designed as a **long-term resume project**, focusing on **clean system design, AI integration, and developer-focused UI/UX**, rather than relying solely on proprietary APIs.

---

## âœ¨ Motivation

Writing correct code is not enough â€” writing **clean, readable, and maintainable code** is equally important.

This project aims to:

* Help developers improve their code quality
* Simulate feedback from a **senior software engineer**
* Explore the practical use of **LLMs for automated code review**
* Compare proprietary and open-source AI models in later phases

---

## ðŸš€ Phase 1 Overview (Current)

**Phase 1 focuses on building a reliable, end-to-end baseline system** using an LLM to provide structured code feedback.

> Later phases will introduce open-source models, static analysis, and model comparison.

---

## ðŸ§© Features (Phase 1)

### âœ… Code Input Interface

* VS Codeâ€“like editor using **Monaco Editor**
* Syntax highlighting
* Language selection (Python, JavaScript, C++)
* Clean, developer-friendly UI (Dark mode)

---

### ðŸ¤– AI-Powered Code Review

* Uses **GPT-3.5** as a baseline reviewer
* AI is prompted to behave like a **senior software engineer**
* Reviews code for:

  * Readability
  * Logical correctness (basic)
  * Naming conventions
  * Code structure
  * Best practices
  * Potential edge cases

---

### ðŸ“Š Structured Feedback Output

Feedback is returned in **structured JSON format**, not plain text:

* âœ… Strengths
* âš ï¸ Issues
* ðŸ’¡ Suggestions
* ðŸš€ Optimization opportunities
* ðŸ§  Edge cases to consider

This makes feedback:

* Easy to display
* Easy to extend
* Easy to compare across models (future phases)

---

### ðŸ›¡ï¸ Error Handling

* Empty code input validation
* Unsupported language handling
* Graceful fallback for AI/API failures

---

## ðŸ”„ System Flow Diagram

```text
User
 â”‚
 â”‚ writes code
 â–¼
Frontend (React + Monaco Editor)
 â”‚
 â”‚ POST /analyze
 â–¼
Backend API (Node.js / FastAPI)
 â”‚
 â”‚ build prompt
 â”‚ call LLM (GPT-3.5)
 â–¼
LLM Response (JSON)
 â”‚
 â”‚ parse & validate
 â–¼
Structured Feedback
 â”‚
 â–¼
Frontend Feedback Dashboard
```

---

## ðŸ§± Tech Stack

### Frontend

* **React (Vite)**
* **Tailwind CSS**
* **Monaco Editor**
* Axios / Fetch API

---

### Backend

* **Node.js + Express**
  *(FastAPI alternative supported)*
* REST API architecture
* Environment-based configuration (`.env`)

---

### AI / LLM

* **GPT-3.5 (Baseline Model)**
* Prompt-engineered for structured code reviews
* JSON-only response format for reliability

---

## ðŸ“¦ API Design

### `POST /analyze`

#### Request Body

```json
{
  "language": "python",
  "code": "def add(a, b): return a + b"
}
```

#### Response Body

```json
{
  "strengths": [],
  "issues": [],
  "suggestions": [],
  "optimizations": [],
  "edge_cases": []
}
```

---

## ðŸ§  Prompt Design Strategy

The LLM is instructed to:

* Act as a **senior software engineer**
* Review code written by a junior developer
* Return feedback **strictly in JSON format**

This ensures:

* Consistency
* Easy parsing
* Extensibility for future phases

---

## ðŸ“ Project Structure

```text
ai-code-feedback/
â”‚
â”œâ”€â”€ frontend/
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ components/
â”‚   â”‚   â”œâ”€â”€ pages/
â”‚   â”‚   â”œâ”€â”€ App.jsx
â”‚   â”‚   â””â”€â”€ main.jsx
â”‚
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ routes/
â”‚   â”œâ”€â”€ services/
â”‚   â”‚   â””â”€â”€ aiService.js
â”‚   â”œâ”€â”€ app.js
â”‚   â””â”€â”€ .env
â”‚
â”œâ”€â”€ README.md
â””â”€â”€ .gitignore
```

---

## âœ… Phase 1 Completion Criteria

Phase 1 is considered complete when:

* Code editor works smoothly
* Feedback is structured and readable
* UI is clean and professional
* AI responses are fast and reliable
* No crashes during normal usage

---

## ðŸ”® Roadmap

* **Phase 2:** Integrate open-source LLMs (Code LLaMA via cloud inference)
* **Phase 3:** Hybrid system (static code analysis + AI reasoning)
* **Phase 4:** Model comparison & optimization analysis
* **Phase 5:** Technical blog and evaluation report

---

## ðŸ“Œ Resume Highlight

> Built a full-stack AI-powered code review platform that analyzes user-submitted code and provides structured feedback on readability, correctness, and best practices using large language models.

---

## ðŸ§  Key Learnings (So Far)

* Designing AI systems requires **structure and constraints**
* Model-agnostic architecture enables easy upgrades
* UI clarity is as important as AI accuracy
* Structured outputs dramatically improve reliability

---

## ðŸ“œ License

This project is for educational and portfolio purposes.

---


